{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elsevier download code\n",
    "\n",
    "- Developed by Santhanakrishnan Narayanan (n.santhanakrishnan@gmail.com)\n",
    "\n",
    "This script can be used to download article details using the elsevier API. The keyword to be searched is specified in the variable `query`. Before running the script, make sure that your SCOPUS key is entered in `X_ELS_APIKey`. API documentation can be found at https://api.elsevier.com/documentation/SCOPUSSearchAPI.wadl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#articles.StoreMagics.autorestore = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ELS_APIKey = ''\n",
    "\n",
    "\n",
    "count = 1\n",
    "start = 0\n",
    "\n",
    "url = 'https://api.elsevier.com/content/search/scopus'\n",
    "headers = {'X-ELS-APIKey': X_ELS_APIKey}\n",
    "entries = []\n",
    "\n",
    "while count == 1:\n",
    "    query = '?query= {}' #Enter the keyword inside the braces\n",
    "    query += '&date=1950-2020'\n",
    "    query += '&sort=relevance'\n",
    "    query += '&subj=ENGI'\n",
    "    query += '&start=%d' % (start)\n",
    "    query += '&count=%d' % (count)\n",
    "    r = requests.get(url + query, headers=headers)\n",
    "    if 'entry' in r.json()['search-results']: \n",
    "        entries += r.json()['search-results']['entry']\n",
    "        start += 1\n",
    "    else:\n",
    "        count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch relevent information and store it in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'articles' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "articles = pd.DataFrame(columns=['title', 'creator', 'publisher', 'date', 'doi', 'citations' ])\n",
    "hrefs = []\n",
    "publicationTitle = []\n",
    "publicationAuthor = []\n",
    "publicationName = []\n",
    "publicationDate = []\n",
    "publicationDoi = []\n",
    "publicationCitations = []\n",
    "\n",
    "for entry in entries:\n",
    "    title = entry['dc:title']\n",
    "    publicationTitle.append(title)\n",
    "    \n",
    "    if 'dc:creator' in entry:\n",
    "        author = entry['dc:creator']\n",
    "        publicationAuthor.append(author)\n",
    "    else:\n",
    "        author = 'No author'\n",
    "        publicationAuthor.append(author)\n",
    "    \n",
    "    if 'prism:publicationName' in entry:\n",
    "        name = entry['prism:publicationName']\n",
    "        publicationName.append(name)\n",
    "    else:\n",
    "        name = 'No publication name'\n",
    "        publicationName.append(name)\n",
    "    \n",
    "    date = entry['prism:coverDate']\n",
    "    publicationDate.append(date)\n",
    "    \n",
    "    if 'prism:doi' in entry:\n",
    "        doi = entry['prism:doi']\n",
    "        publicationDoi.append(doi)\n",
    "    else:\n",
    "        doi = 'No Doi'\n",
    "        publicationDoi.append(doi)\n",
    "        \n",
    "    if 'citedby-count' in entry:\n",
    "        citations = entry['citedby-count']\n",
    "        publicationCitations.append(citations)\n",
    "    else:\n",
    "        citations = 'No data'\n",
    "        publicationCitations.append(citations)\n",
    "    \n",
    "articles['title'] = publicationTitle\n",
    "articles['creator'] = publicationAuthor\n",
    "articles['publisher'] = publicationName\n",
    "articles['date'] = publicationDate\n",
    "articles['doi'] = publicationDoi\n",
    "articles['citations'] = publicationCitations\n",
    "%store articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles.to_csv('scopusQueryResults.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs = []\n",
    "for entry in entries:\n",
    "    #title = entry['dc:title']\n",
    "    #creator = entry['dc:creator']\n",
    "    #publicationName = entry['prism:publicationName']\n",
    "    links = entry['link']\n",
    "    for link in links:\n",
    "        if link['@ref'] == 'full-text':\n",
    "            href = link['@href']\n",
    "            hrefs.append(href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "articlesFull = pd.DataFrame(columns=['url', 'title', 'creators', 'subjects', 'description', 'publicationName'])\n",
    "for url in hrefs:\n",
    "    article = {}\n",
    "    article['url'] = url\n",
    "    r = requests.get(url, headers=headers)\n",
    "    root = ET.fromstring(r.text)\n",
    "    article['title'] = root.find('{http://www.elsevier.com/xml/svapi/article/dtd}coredata').find('{http://purl.org/dc/elements/1.1/}title').text\n",
    "    article['creators'] = [x.text for x in root.find('{http://www.elsevier.com/xml/svapi/article/dtd}coredata').findall('{http://purl.org/dc/elements/1.1/}creator')]\n",
    "    article['subjects'] = [x.text for x in root.find('{http://www.elsevier.com/xml/svapi/article/dtd}coredata').findall('{http://purl.org/dc/terms/}subject')]\n",
    "    article['description'] = root.find('{http://www.elsevier.com/xml/svapi/article/dtd}coredata').find('{http://purl.org/dc/elements/1.1/}description').text\n",
    "    article['publicationName'] = root.find('{http://www.elsevier.com/xml/svapi/article/dtd}coredata').find('{http://prismstandard.org/namespaces/basic/2.0/}publicationName').text\n",
    "    if article['description']:\n",
    "        articlesFull = articlesFull.append(article, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "articlesFull.to_csv('autonomous mobility on demand full.csv', sep=',', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
